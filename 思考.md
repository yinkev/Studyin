# 思考 - Reasoning & Thought Process

> **Living Document**: Capture design philosophy, reasoning, and思路 (thought patterns)

Last Updated: 2025-10-09

---

## 设计哲学 (Design Philosophy)

### Core Principle: Psychology-First → Design → Function

```
心理学 (Psychology)
    ↓
设计 (Design)
    ↓
功能 (Function)
```

**Why This Order?**

**Traditional Approach** ❌:
1. Build features first
2. Add design later
3. Hope users like it

**Our Approach** ✅:
1. **Understand psychology**: How do medical students learn? What causes anxiety?
2. **Design for psychology**: Create experiences that reduce stress, increase engagement
3. **Build features**: Implement what psychology and design dictate

**Example**:
```
Problem: Medical students feel overwhelmed studying

Traditional Solution:
- Build flashcard app
- Add lots of features
- Hope it reduces overwhelm

Psychology-First Solution:
- Research: Cognitive load theory, spaced repetition, self-determination theory
- Design: Soft colors reduce anxiety, progress visible reduces uncertainty
- Features: Adaptive difficulty, clear progress, achievement system
```

---

## 学习科学思维 (Learning Science Thinking)

### Why Gamification for Medical Learning?

**认知负荷理论 (Cognitive Load Theory)**:
- Medical content has HIGH intrinsic load (complex)
- Reduce extraneous load (unnecessary complexity)
- Optimize germane load (learning-focused effort)

**Implementation**:
```python
# Bad: High extraneous load
interface = ComplexUI()  # Distracting
content = EverythingAtOnce()  # Overwhelming

# Good: Optimized cognitive load
interface = SoftKawaiiUI()  # Calming, reduces anxiety
content = AdaptivePacing()  # Right difficulty, right time
gamification = ClearProgress()  # Visible achievement
```

**自我决定理论 (Self-Determination Theory)**:
- **Autonomy**: User controls learning path
- **Competence**: Clear progress feedback
- **Relatedness**: AI coach provides connection

**Implementation**:
- Skill tree: User chooses path (autonomy)
- XP/levels: Visible competence growth
- AI coach: Socratic teaching, not lecturing (relatedness)

**间隔重复 (Spaced Repetition)**:
- SM-2 algorithm proven effective
- Reduces forgetting curve
- Optimizes review timing

---

## 技术决策思路 (Technical Decision Thinking)

### Why No Docker?

**思路**:
```
User request: "I do not want to use docker"

思考过程:
1. User explicit preference → Respect it
2. Personal use project → Complexity not needed
3. Local control → Better for debugging
4. System services → Reliable on macOS/Linux

Decision: Local PostgreSQL, Redis, Qdrant
Benefit: Simpler, more control, no overhead
Trade-off: Manual installation, version management
```

**Learning**: User preferences >> theoretical "best practices"

---

### Why Everything Dynamic (No Hardcoding)?

**思路**:
```
User request: "Everything also has to be dynamic. Not hardcoded"

思考过程:
1. Flexibility: Change without code changes
2. Testing: Different configs for different environments
3. Feature flags: Enable/disable features dynamically
4. Future: Easy to add admin controls

Decision: Pydantic Settings + env vars
Benefit: Maximum flexibility, testability
Trade-off: More initial setup, validation needed
```

**Example Thought Process**:
```python
# Initial thought: "This is simple, just hardcode"
XP_PER_QUESTION = 10  # ❌ Quick but inflexible

# Better thought: "What if we want to change this later?"
class Settings(BaseSettings):
    XP_PER_QUESTION: int = 10  # ✅ Dynamic, configurable

# Even better thought: "What if different question types have different XP?"
class Settings(BaseSettings):
    XP_BASIC_QUESTION: int = 10
    XP_ADVANCED_QUESTION: int = 25
    XP_CLINICAL_CASE: int = 50
    # ✅ Flexible, future-proof
```

**Learning**: Always think 2-3 steps ahead. Today's hardcode = tomorrow's pain.

---

### Why Codex CLI with OAuth (No API Keys)?

**思路**:
```
Problem: Need LLM integration for RAG, AI coach, questions

Option A: API Keys
- Pros: Simple integration
- Cons: Key management, rotation, security risk
- 思考: What if key leaks? Rotation pain?

Option B: Codex CLI OAuth
- Pros: No key management, better security, ChatGPT integration
- Cons: OAuth flow complexity
- 思考: One-time OAuth setup >> ongoing key management

Decision: Codex CLI OAuth
Reasoning: Security + simplicity long-term
```

**Implementation Thought Process**:
```python
# Bad thought: "Let's hardcode API key for now"
api_key = "sk-..."  # ❌ Security risk

# Better thought: "Use environment variable"
api_key = os.getenv("OPENAI_API_KEY")  # ⚠️ Still manual key management

# Best thought: "Use OAuth, no keys at all"
client = Anthropic()  # ✅ OAuth, no key needed
# One-time: codex (ChatGPT sign-in)
```

**Learning**: Choose complexity in setup over complexity in maintenance.

---

### Why Next.js 15 App Router (Not Pages Router)?

**思路**:
```
Question: Which Next.js routing?

考虑因素:
1. Modern: App Router is 2025 standard
2. Performance: Server Components faster
3. Future-proof: Pages Router legacy
4. Learning curve: Yes, but worth it

Decision: App Router
Reasoning: Initial complexity << long-term benefits
```

**Thought Pattern**:
- ✅ Choose modern patterns (avoid tech debt)
- ✅ Learn new patterns early (compound benefit)
- ❌ Avoid "legacy" just because familiar

---

### Why PostgreSQL + pgvector (Not Dedicated Vector DB Initially)?

**思路**:
```
Problem: Need vector storage for embeddings

思考过程:
1. MVP Scale: How many vectors? ~10K-100K (manageable)
2. Complexity: One DB vs two DBs?
3. Performance: pgvector sufficient for MVP?
4. Migration: Can we add Qdrant later if needed?

Decision Matrix:
                    PostgreSQL+pgvector    Qdrant
Setup Complexity:   Low                    Medium
Performance (MVP):  Sufficient             Better
Operational Load:   Low (one DB)           Higher (two DBs)
Scalability:        Medium                 High
Migration Path:     Easy to add Qdrant     N/A

Decision: Start with PostgreSQL+pgvector, add Qdrant if needed
```

**Learning**: Optimize for current needs, keep migration path open.

**Migration Thought Process**:
```python
# Phase 2-4 (MVP): PostgreSQL+pgvector
class MaterialChunk(Base):
    embedding: Vector(1536)  # Simple, one DB

# Future (if needed): Add Qdrant
class MaterialChunk(Base):
    qdrant_id: UUID  # Reference to Qdrant
    # PostgreSQL: relational data
    # Qdrant: vector search
```

**思路**: Don't over-engineer. Start simple, evolve when needed.

---

## UI/UX 思维 (UI/UX Thinking)

### Why Soft Kawaii UI for Medical Content?

**Initial思考**:
```
Problem: Medical studying is stressful, anxiety-inducing

传统方法:
- Serious, professional UI
- Clinical colors (white, blue, gray)
- Dense information presentation
- Result: More stress, less engagement

心理学洞察:
- Soft colors reduce cortisol (stress hormone)
- Playful elements increase dopamine (motivation)
- Clear progress reduces uncertainty anxiety
- Achievement unlocks provide reward feedback

Decision: Soft Kawaii UI with subtle pixel accents
```

**Design Reasoning**:
```
UI Chrome (Playful):
- Soft pastels (light blues, pinks, greens)
- Rounded corners (friendly, approachable)
- Pixel art mascot (companion, not intimidating)
- Smooth animations (delightful, not distracting)

Medical Content (Professional):
- High contrast text (readability)
- Clean sans-serif fonts (clarity)
- Proper medical terminology
- No pixel fonts for critical info

Separation Strategy:
- Form: Kawaii → Reduces anxiety
- Content: Professional → Maintains credibility
```

**思路**: Balance playfulness with professionalism. Serious learning ≠ serious-looking interface.

---

### Why Gamification for Medical Students?

**心理学分析**:
```
Medical Student Psychology:
- High stress (exam pressure)
- Long study hours (motivation fatigue)
- Complex content (cognitive overload)
- Delayed feedback (exam results weeks later)

Gamification Solutions:
1. XP/Levels → Immediate feedback (dopamine)
2. Streaks → Habit formation (consistency)
3. Achievements → Progress visibility (competence)
4. Rewards → Intrinsic motivation (autonomy)

Not Just "Fun":
- Gamification as psychological intervention
- Addresses specific pain points
- Evidence-based design
```

**Implementation思路**:
```python
# Bad gamification: Random points
def award_xp():
    user.xp += 10  # Why 10? Arbitrary!

# Good gamification: Psychologically motivated
def award_xp(task_difficulty, performance, effort):
    """
    Difficulty: Harder tasks = more XP (effort valuation)
    Performance: Better performance = bonus (competence)
    Effort: Time spent = effort recognition (process reward)
    """
    base_xp = settings.XP_BASE * task_difficulty
    performance_bonus = base_xp * (performance - 0.5)  # Above 50% = bonus
    effort_bonus = min(effort_seconds / 60, 10)  # Cap at 10 min

    total_xp = base_xp + performance_bonus + effort_bonus
    return total_xp
```

**思路**: Every game mechanic should have psychological justification.

---

## RAG Pipeline 思维 (RAG Thinking)

### Why Semantic Chunking (Not Fixed-Size)?

**思考过程**:
```
Problem: Convert documents to chunks for embedding

Option A: Fixed-size chunks
- Simple: Every 512 tokens
- Problem: Splits mid-sentence, mid-concept

Option B: Semantic chunks
- Complex: Detect logical boundaries
- Benefit: Preserves meaning, better retrieval

思路:
- Medical content has natural boundaries:
  - Sections (anatomy, physiology, pathology)
  - Concepts (disease mechanism, treatment)
  - Clinical vignettes (case descriptions)

- Breaking mid-concept = poor retrieval
- Semantic boundaries = better context

Decision: Semantic chunking with overlap
```

**Implementation Thought**:
```python
# Bad: Fixed-size (destroys context)
chunks = [text[i:i+512] for i in range(0, len(text), 512)]

# Better: Sentence-aware
chunks = split_on_sentences(text, max_tokens=512)

# Best: Semantic-aware
chunks = split_on_semantic_boundaries(
    text,
    max_tokens=512,
    overlap=128,  # Preserve context across chunks
    boundary_types=['section', 'concept', 'paragraph']
)
```

**学习**: Structure in data → better retrieval. Don't destroy structure for simplicity.

---

### Why RAG + LLM (Not Fine-tuning)?

**思路分析**:
```
Goal: Medical teaching with personalized content

Option A: Fine-tune LLM on medical data
- Pros: Model "knows" medical content
- Cons: Expensive, static, hard to update, user content not included

Option B: RAG (Retrieval Augmented Generation)
- Pros: Dynamic, user content, updatable, cheaper
- Cons: Retrieval quality critical

Decision Matrix:
                Fine-tuning    RAG
Cost:           High ($$$)     Low ($)
User Content:   Hard           Easy
Updates:        Re-train       Add to DB
Personalization: Hard          Easy
Medical Safety:  Risk          Verifiable (show sources)

Decision: RAG
Reasoning: User uploads their own materials → RAG is only option
```

**Safety Thought Process**:
```python
# Fine-tuning risk:
model.generate("Treatment for X")
# → Output hallucination? Can't verify source.

# RAG safety:
chunks = retrieve_relevant_chunks(query)
response = llm.generate(
    context=chunks,
    query=query
)
# → Can show sources, verify against user's materials
# → Reduces hallucination risk
```

**思路**: For medical content, verifiability > performance. RAG provides transparency.

---

## 异步思维 (Async Thinking)

### Why Async Everything?

**思考**:
```
Problem: FastAPI server needs to handle:
- File uploads (slow I/O)
- Document processing (CPU-intensive)
- LLM calls (network I/O, slow)
- Database queries (I/O)

同步方法 (Synchronous):
- One request blocks one worker
- 10 concurrent uploads = 10 workers blocked
- Poor resource utilization

异步方法 (Asynchronous):
- I/O operations don't block
- One worker handles many concurrent requests
- Better resource utilization

Decision: Async/await everywhere
```

**Implementation Pattern**:
```python
# ❌ Synchronous (blocks worker)
@app.post("/upload")
def upload_file(file: UploadFile):
    content = file.read()  # Blocks
    chunks = process_document(content)  # Blocks
    embeddings = generate_embeddings(chunks)  # Blocks
    db.save(embeddings)  # Blocks
    return {"status": "done"}

# ✅ Asynchronous (non-blocking)
@app.post("/upload")
async def upload_file(file: UploadFile):
    content = await file.read()  # Doesn't block
    chunks = await process_document(content)  # Background
    embeddings = await generate_embeddings(chunks)  # Doesn't block
    await db.save(embeddings)  # Doesn't block
    return {"status": "done"}
```

**思路**: I/O-bound operations = always async. CPU-bound = background jobs.

---

## 错误处理思维 (Error Handling Thinking)

### Why Graceful Degradation?

**场景思考**:
```
Problem: What if Codex CLI is down?

Option A: Fail hard
- LLM down → App broken
- Poor user experience

Option B: Graceful degradation
- LLM down → Show cached content
- LLM down → Show pre-generated questions
- LLM down → Disable AI features, core app works

Decision: Graceful degradation
```

**Implementation思路**:
```python
# ❌ Fail hard
async def get_ai_response(query: str):
    return await llm.generate(query)  # If fails, app breaks

# ✅ Graceful degradation
async def get_ai_response(query: str) -> AIResponse:
    try:
        return await llm.generate(query)
    except LLMError as e:
        logger.error(f"LLM failed: {e}")

        # Fallback strategies:
        # 1. Return cached response
        cached = await cache.get(query)
        if cached:
            return AIResponse(
                content=cached,
                is_cached=True,
                error_msg="Using cached response"
            )

        # 2. Return helpful error
        return AIResponse(
            content="AI coach temporarily unavailable. Please try again.",
            is_error=True,
            error_msg=str(e)
        )
```

**思路**: Never let external dependencies break core functionality.

---

## 测试思维 (Testing Thinking)

### Why Test-Driven for Critical Logic?

**思考**:
```
Critical Logic Examples:
- SM-2 spaced repetition algorithm
- XP calculation
- Progress tracking
- Answer evaluation

Question: Write tests before or after?

Before (TDD):
- Define expected behavior first
- Catch bugs early
- Better design (testable = good design)

After:
- Faster initial development
- Risk: Forget to test edge cases
- Risk: Design not testable

Decision: TDD for critical logic, pragmatic for UI
```

**Example思路**:
```python
# Phase 5: SM-2 Algorithm
# TDD Approach:

# 1. Write test FIRST
def test_sm2_correct_answer():
    """Correct answer should increase interval and EF"""
    result = calculate_next_review(
        quality=4,  # Good answer
        repetition=1,
        easiness_factor=2.5,
        interval=1
    )

    assert result.interval > 1  # Interval increases
    assert result.easiness_factor >= 2.5  # EF stays or increases
    assert result.repetition == 2

# 2. Test FAILS (no implementation yet)

# 3. Write implementation
def calculate_next_review(...):
    # Implement SM-2 algorithm
    pass

# 4. Test PASSES
```

**思路**: For algorithms with proven correct behavior, TDD ensures correctness.

---

## 安全思维 (Security Thinking)

### Why JWT + Refresh Tokens?

**安全分析**:
```
Problem: User authentication

Option A: Session cookies
- Pros: Simple, stateful
- Cons: Server memory, scaling issues

Option B: JWT only
- Pros: Stateless, scalable
- Cons: Can't revoke easily

Option C: JWT + Refresh tokens
- Pros: Scalable + revocable
- Cons: More complex

思考过程:
1. Access token (short-lived): 15 min
   - Stolen? Limited damage (expires soon)
2. Refresh token (long-lived): 7 days
   - Stored in DB (can revoke)
   - Used to get new access token

Decision: JWT + Refresh tokens
Reasoning: Balance security and UX
```

**Implementation思路**:
```python
# Login flow:
@app.post("/login")
async def login(creds: Credentials):
    user = await authenticate(creds)

    access_token = create_jwt(
        user_id=user.id,
        expires_in=timedelta(minutes=15)  # Short-lived
    )

    refresh_token = create_refresh_token(
        user_id=user.id,
        expires_in=timedelta(days=7)  # Long-lived
    )

    await db.save_refresh_token(refresh_token)  # Can revoke

    return {
        "access_token": access_token,
        "refresh_token": refresh_token
    }

# Refresh flow:
@app.post("/refresh")
async def refresh(token: str):
    # Verify token exists in DB (not revoked)
    if not await db.refresh_token_valid(token):
        raise HTTPException(401, "Invalid token")

    new_access_token = create_jwt(...)
    return {"access_token": new_access_token}
```

**思路**: Security layers: Short-lived access + revocable refresh.

---

## 性能思维 (Performance Thinking)

### Why Caching Strategy?

**性能分析**:
```
Slow Operations:
1. LLM calls: 2-5 seconds
2. Vector search: 100-500ms
3. Complex aggregations: 500ms-2s

Without Caching:
- Every request = slow
- Poor UX
- High LLM costs

With Caching:
- Repeated queries = fast
- Better UX
- Lower costs

Decision: Multi-tier caching
```

**Caching思路**:
```python
# Tier 1: In-memory (fastest)
@cache.memoize(timeout=300)  # 5 min
async def get_user_stats(user_id: UUID):
    return await db.calculate_stats(user_id)

# Tier 2: Redis (fast, shared)
async def get_ai_response(query: str):
    # Check Redis first
    cached = await redis.get(f"ai:{hash(query)}")
    if cached:
        return cached

    # Generate and cache
    response = await llm.generate(query)
    await redis.setex(
        f"ai:{hash(query)}",
        timeout=3600,  # 1 hour
        value=response
    )
    return response

# Tier 3: Database (persistent)
# Materialized views for complex aggregations
```

**思路**: Cache at appropriate layer: Memory > Redis > DB > Compute.

---

## 扩展思维 (Scalability Thinking)

### Why Design for Personal Use but Plan for Scale?

**思考**:
```
Current: Personal use (1 user)
Future: Maybe friends, classmates, study groups?

Design Approach:
- Implement: Personal use (simple)
- Architecture: Multi-user ready (prepared)

Example: User isolation
```

**Implementation思路**:
```python
# ❌ Personal use only (hard to scale)
class Material(Base):
    id: UUID
    title: str
    # No user_id! Assumes single user

# ✅ Personal use, scale-ready
class Material(Base):
    id: UUID
    user_id: UUID  # Even for single user
    title: str

    # Easy to add later:
    # - Multi-user
    # - Sharing
    # - Permissions

# Queries always filter by user
materials = await db.query(Material).filter(
    Material.user_id == current_user.id  # Isolation
).all()
```

**思路**: Zero-cost abstraction. Add user_id now, use later if needed.

---

## 决策框架 (Decision Framework)

### How to Make Architectural Decisions?

**框架**:
```
1. Understand Constraints
   - User requirements (explicit)
   - Project constraints (time, budget, scope)
   - Technical constraints (platform, language)

2. Identify Options
   - Research alternatives
   - List pros/cons
   - Consider trade-offs

3. Evaluate Impact
   - Short-term: Implementation complexity?
   - Long-term: Maintenance burden?
   - Reversibility: Can we change later?

4. Document Decision
   - Why chosen?
   - What rejected?
   - What consequences?
   - ADR (Architecture Decision Record)

5. Review Outcomes
   - Did it work?
   - Update ADR with results
   - Learn for next decision
```

**Example Application**: ADR-005 (PostgreSQL + pgvector)
```
1. Constraints: Need vector storage, prefer simple MVP
2. Options: PostgreSQL+pgvector, Qdrant, Pinecone
3. Impact:
   - PostgreSQL: One DB, simpler, sufficient for MVP
   - Qdrant: Better performance, more complex
   - Pinecone: Cloud, cost, network dependency
4. Document: Created ADR-005
5. Review: Will update after Phase 2 implementation
```

---

## 学习点 (Lessons Learned)

### Lesson 1: User Preferences > "Best Practices"

**场景**: User said "no Docker"

**Initial Thought**: "But Docker is best practice for consistency!"

**Realization**: For personal use, local services are simpler and user prefers it.

**Learning**: Context matters. "Best practices" are contextual, not universal.

---

### Lesson 2: Dynamic Config from Day 1

**场景**: User said "everything dynamic, not hardcoded"

**Initial Thought**: "Can hardcode for MVP, refactor later"

**Realization**: Hardcoding now = technical debt tomorrow. Dynamic from start is easier.

**Learning**: Future-proof early decisions. Harder to change later.

---

### Lesson 3: Documentation is Development

**场景**: Creating living documents (AGENTS.md, CLAUDE.md, DECISIONS.md, etc.)

**Initial Thought**: "Just code, document later"

**Realization**: Documentation clarifies thinking, catches inconsistencies, guides development.

**Learning**: Good documentation = good design. Write docs as you design.

---

### Lesson 4: Psychology-First Actually Works

**场景**: Designing UI and gamification

**Initial Thought**: "Just make it look nice"

**Realization**: Understanding psychology → better design decisions → better UX → better learning outcomes.

**Learning**: Start with "why" (psychology), not "what" (features).

---

## 下一步思考 (Next Steps Thinking)

### Phase 0 准备 (Phase 0 Preparation)

**当前状态**: Planning complete, ready to start implementation

**思考检查清单**:
- [ ] All architectural decisions documented (DECISIONS.md)
- [ ] All living documents created (AGENTS.md, CLAUDE.md, CHANGELOG.md, 思考.md)
- [ ] Tech stack finalized (TECH_STACK.md)
- [ ] Phase plan clear (PHASES.md)
- [ ] Setup guide ready (QUICKSTART.md)

**准备开始 Phase 0 时**:
1. Follow QUICKSTART.md step-by-step
2. Check off Phase 0 todos in PHASES.md
3. Use agents as planned in AGENTS.md
4. Document decisions in DECISIONS.md
5. Update CHANGELOG.md with progress
6. Update 思考.md with learnings

---

## 持续改进 (Continuous Improvement)

### How to Update This Document?

**When to Update**:
- After making architectural decisions
- When discovering new思路 or patterns
- After solving complex problems
- When learning from mistakes
- After completing phases

**What to Add**:
- **思考过程**: How did we think through problems?
- **决策理由**: Why did we choose this approach?
- **Trade-offs**: What did we give up?
- **学习点**: What did we learn?
- **改进想法**: How could we do better next time?

**Format**:
```markdown
### [Topic]

**思考**:
[Thought process]

**决策**:
[What we decided]

**思路**:
[Reasoning pattern]

**学习**:
[What we learned]
```

---

## Changelog

### 2025-10-09
- Created 思考.md as living document for reasoning and thought process
- Documented design philosophy (Psychology-First → Design → Function)
- Captured learning science thinking
- Documented technical decision-making patterns
- Added UI/UX reasoning
- Included async, error handling, testing, security, and performance thinking
- Documented decision framework
- Added lessons learned
- Created continuous improvement process

---

**Remember**: 思考 (thinking) is as important as 实现 (implementation). Good思路 → good code. Update this document continuously.
